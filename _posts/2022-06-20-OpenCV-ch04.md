---
layout: single

---
# 한니발 씌우기
```
import cv2, numpy as np

face_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_frontalface_alt.xml')
Hannibal = cv2.imread('./images/mask_hannibal.png')

assert Hannibal is not None #h_mask, w_mask = Hannibal.shape[:2]
cv2.imshow('Hannibal: face_mask ', Hannibal)
if face_cascade.empty() :
    raise IOError('Error: face cascade xml file')

# load an image
img = cv2.imread('./images/Joe_Biden_3.jpg')
img = cv2.resize(img, None, fx=0.5, fy=0.5)
cv2.imshow('img', img)

# face detection
face_rects = face_cascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=2)

for (x, y, w, h) in face_rects:
    # 마스크에 맞게 관심영역 설정
    y = y + int(0.2*h)
    img_roi = img[y:y+h, x:x+w] # 관심영역
    # 관심영역 크기에 맞게 마스크 사이즈 변경(resize)
    Hannibal_small = cv2.resize(Hannibal, (w, h))
    # gray로 변환, 180이상인 부분은 255로
    gray_Hannibal = cv2.cvtColor(Hannibal_small, cv2.COLOR_BGR2GRAY)
    ret, Hannibal_mask = cv2.threshold(gray_Hannibal, 200, 255, cv2.THRESH_BINARY_INV)
    # 200보다 작은 부분을 255(하얗게)
    #kernel = np.ones((3,3), np.uint8)
    #mask=cv2.erode(mask, kernel, iterations=1); mask=cv2.dilate(mask, kernel, iterations=1)
    # mask_inv
    face_mask = cv2.bitwise_not(Hannibal_mask) # Hannibal_mask의 역(255 <-> 0 바꿈)

    cv2.imshow('Hannibal_mask', Hannibal_mask)
    cv2.imshow('face_mask', face_mask)
    masked_face = cv2.bitwise_and(Hannibal_small, Hannibal_small, mask=Hannibal_mask)
    # 크기 조정한 mask(배경은 0)
    masked_img = cv2.bitwise_and(img_roi, img_roi, mask=face_mask)  # 관심영역(mask영역은 0)
    cv2.imshow('masked_face', masked_face)
    cv2.imshow('overlapped_img', masked_img)
    #
    img[y:y + h, x:x + w] = cv2.add(masked_face, masked_img)
cv2.imshow('Face with mask', img)
c = cv2.waitKey()
cv2.destroyAllWindows()
```

# 비디오캡쳐 눈 검출
```
import cv2
import numpy as np

face_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_frontalface_alt.xml')
eye_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_eye.xml')
if face_cascade.empty():
    raise IOError('Unable to load the face cascade classifier xml file')

if eye_cascade.empty():
    raise IOError('Unable to load the eye cascade classifier xml file')

cap = cv2.VideoCapture(0)
ds_factor = 0.5

while True:
    ret, frame = cap.read()
    frame = cv2.resize(frame, None, fx=ds_factor, fy=ds_factor)
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    #얼굴검출
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=3)
    for (x, y, w, h) in faces:
        #영역줄임
        roi_gray = gray[y:y + h, x:x + w]
        roi_color = frame[y:y + h, x:x + w]
        eyes = eye_cascade.detectMultiScale(roi_gray)
        for (x_eye, y_eye, w_eye, h_eye) in eyes:
            center = (int(x_eye + 0.5 * w_eye), int(y_eye + 0.5 * h_eye))
            radius = int(0.3 * (w_eye + h_eye))
            color = (0, 255, 0)
            thickness = 3
            cv2.circle(roi_color, center, radius, color, thickness)

    cv2.imshow('Eye Detector', frame)

    c = cv2.waitKey(1)
    if c == 27:
        break

cap.release()
cv2.destroyAllWindows()
```
# 비디오 캡쳐 얼굴검출
```
import cv2
import numpy as np

face_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_frontalface_alt.xml')

cap = cv2.VideoCapture(1)
scaling_factor = 0.5

if __name__=='__main__':
#CAP_DSHOW	다이렉트쇼(DirectShow)
    cap = cv2.VideoCapture(0,cv2.CAP_DSHOW)

    if not cap.isOpened():
        raise IOError("Cannot open webcam")
    cur_mode = None
scaling_factor = 0.5
while True:
    ret, frame = cap.read()
    frame = cv2.resize(frame, None, fx=scaling_factor,
                       fy=scaling_factor, interpolation=cv2.INTER_AREA)

    face_rects = face_cascade.detectMultiScale(frame, scaleFactor=1.3, minNeighbors=3)
    for (x, y, w, h) in face_rects:
        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)

    cv2.imshow('Face Detector', frame)

    c = cv2.waitKey(1)
    if c == 27:
        break

cap.release()
cv2.destroyAllWindows() 
```
# 얼굴검출 크기별
``` 
import cv2, numpy as np

face_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_frontalface_alt.xml')

while True:
    # 이미지에서 3개만 얼굴 검출되게끔 잘 조절
    frame = cv2.imread('images/images2.jpg')
    frame = cv2.resize(frame, None, fx=1.2, fy=1.2)
    face_rects = face_cascade.detectMultiScale(frame, scaleFactor=1.2, minNeighbors=2)

    # 넓이를 기준으로 내림차순 정렬
    face_rects = list(face_rects)
    face_rects.sort(key=lambda face: face[2] * face[3], reverse=True)

    # 가장 큰 것은 빨간색, 두번 쨰는 주황색, 나머지는 노랑색을 칠한다.
    # 빨간색 칠하고 리스트에서 제거
    if len(face_rects) > 1:
        (x, y, w, h) = face_rects[0]
        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)
        face_rects.remove(face_rects[0])

    # 주황색 칠하고 리스트에서 제거
    if len(face_rects) > 1:
        (x, y, w, h) = face_rects[0]
        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 125, 255), 2)
        face_rects.remove(face_rects[0])

    # 나머지는 전부 노란색으로 칠한다.
    for(x, y, w, h) in face_rects:
        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)

    cv2.imshow('Face Detector', frame)

    c = cv2.waitKey(1)
    if c == 27:
        break

cv2.destroyAllWindows()

```


# 비디오캡쳐 눈에  이미지 씌우기

```
import cv2
import numpy as np

face_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_frontalface_alt.xml')
eye_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_eye.xml')

if face_cascade.empty():
    raise IOError('Unable to load the face cascade classifier xml file')
if eye_cascade.empty():
    raise IOError('Unable to load the eye cascade classifier xml file')

if __name__=='__main__':
#CAP_DSHOW	다이렉트쇼(DirectShow)
    cap = cv2.VideoCapture(0,cv2.CAP_DSHOW)

    if not cap.isOpened():
        raise IOError("Cannot open webcam")



sunglasses_img = cv2.imread('./images/sunglasses.png')

while True:
    ret, frame = cap.read()
    frame = cv2.resize(frame, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)
    vh, vw = frame.shape[:2]
    vh, vw = int(vh), int(vw)

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=1)
    centers = []

    for (x, y, w, h) in faces:
        roi_gray = gray[y:y + h, x:x + w]
        roi_color = frame[y:y + h, x:x + w]
        eyes = eye_cascade.detectMultiScale(roi_gray)
        for (x_eye, y_eye, w_eye, h_eye) in eyes:
            centers.append((x + int(x_eye + 0.5 * w_eye), y + int(y_eye + 0.5 * h_eye)))

    if len(centers) > 1:  # if detects both eyes
        h, w = sunglasses_img.shape[:2]
        # Extract the region of interest from the image
        eye_distance = abs(centers[1][0] - centers[0][0])
        # Overlay sunglasses; the factor 2.12 is customizable depending on the size of the face
        sunglasses_width = 2.12 * eye_distance
        scaling_factor = sunglasses_width / w
        print(scaling_factor, eye_distance)
        overlay_sunglasses = cv2.resize(sunglasses_img, None, fx=scaling_factor, fy=scaling_factor,
                                        interpolation=cv2.INTER_AREA)

        x = centers[0][0] if centers[0][0] < centers[1][0] else centers[1][0]

        # customizable X and Y locations; depends on the size of the face
        x -= int(0.26 * overlay_sunglasses.shape[1])
        y += int(0.26 * overlay_sunglasses.shape[0])

        h, w = overlay_sunglasses.shape[:2]
        h, w = int(h), int(w)
        frame_roi = frame[y:y + h, x:x + w]
        # Convert color image to grayscale and threshold it
        gray_overlay_sunglassess = cv2.cvtColor(overlay_sunglasses, cv2.COLOR_BGR2GRAY)
        ret, mask = cv2.threshold(gray_overlay_sunglassess, 180, 255, cv2.THRESH_BINARY_INV)

        # Create an inverse mask
        mask_inv = cv2.bitwise_not(mask)

        try:
            # Use the mask to extract the face mask region of interest
            masked_face = cv2.bitwise_and(overlay_sunglasses, overlay_sunglasses, mask=mask)
            # Use the inverse mask to get the remaining part of the image
            masked_frame = cv2.bitwise_and(frame_roi, frame_roi, mask=mask_inv)
        except cv2.error as e:
            print('Ignoring arithmentic exceptions: ' + str(e))
            # raise e

        # add the two images to get the final output
        frame[y:y + h, x:x + w] = cv2.add(masked_face, masked_frame)
    else:
        print('Eyes not detected')

    cv2.imshow('Eye Detector', frame)
    c = cv2.waitKey(1)
    if c == 27:
        break

cap.release()
cv2.destroyAllWindows()
```

